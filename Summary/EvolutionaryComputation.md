# Evolutionary Computation (EC)

In this page, we try our best to maintain a (very) short reference list for the **original / seminal / landmark / survey / review** papers for EC, in order to help better understand it especially for newcomers. However, owing to the uncountable paper amount (which still keeps growing everyday), we have to select a *very small* set from *representative* works. *We first apologize for (inevitable) missing references*. Note that how to select from very huge references is a **non-trivial** work, depending on our *definitely biased* and *relatively limited* experiences. Since there are still many other worth-citing papers missed here, we expect to continue to add them if you could report them via [Issues](https://github.com/Evolutionary-Intelligence/DistributedEvolutionaryComputation/issues) or [Pull requests](https://github.com/Evolutionary-Intelligence/DistributedEvolutionaryComputation/pulls).

## Popular Nature/Science Reviews  

* Miikkulainen, R. and Forrest, S., 2021. [A biological perspective on evolutionary computation](https://www.nature.com/articles/s42256-020-00278-8). Nature Machine Intelligence, 3(1), pp.9-15.
* Eiben, A.E. and Smith, J., 2015. [From evolutionary computation to the evolution of things](https://www.nature.com/articles/nature14544). Nature, 521(7553), pp.476-482.
* Forrest, S., 1993. [Genetic algorithms: Principles of natural selection applied to computation](https://www.science.org/doi/10.1126/science.8346439). Science, 261(5123), pp.872-878.

For more details about the **history** and **classification** of EC, refer to the following wonderful books and papers, to name a few:

* Schoenauer, M., 2015. [Evolutionary algorithms](https://link.springer.com/chapter/10.1007/978-94-017-9014-7_28). Handbook of Evolutionary Thinking in the Sciences. Springer.
* De Jong, K.A., 2006. [Evolutionary computation: A unified approach](https://ieeexplore.ieee.org/book/6267245). MIT Press.
  * De Jong, K.A., Fogel, D.B. and Schwefel, H.P., 1997. [A history of evolutionary computation](https://www.taylorfrancis.com/chapters/edit/10.1201/9781482268713-13/history-evolutionary-computation). Handbook of Evolutionary Computation. Oxford University Press.
* Fogel, D.B., 1998. [Evolutionary computation: The fossil record](https://ieeexplore.ieee.org/book/5263042). IEEE Press.
  * Fogel, D.B., 1998. [Unearthing a fossil from the history of evolutionary computation](https://dl.acm.org/doi/10.5555/2379195.2379196). Fundamenta Informaticae, 35(1-4), pp.1-16.
* Back, T., Hammel, U. and Schwefel, H.P., 1997. [Evolutionary computation: Comments on the history and current state](https://ieeexplore.ieee.org/document/585888). IEEE Transactions on Evolutionary Computation, 1(1), pp.3-17.
  * Back, T., 1996. [Evolutionary algorithms in theory and practice: Evolution strategies, evolutionary programming, genetic algorithms](https://academic.oup.com/book/40791). Oxford University Press.

## Genetic Algorithm (GA) [ [Interview](https://users.sussex.ac.uk/~philh/pubs/HollandINTV.pdf) | [CACM](https://cacm.acm.org/magazines/2016/8/205047-adaptive-computation/abstract) ]

* Whitley, D., 2019. [Next generation genetic algorithms: A user’s guide and tutorial](https://link.springer.com/chapter/10.1007/978-3-319-91086-4_8). In Handbook of Metaheuristics (pp. 245-274). Springer, Cham.
  * Whitley, D., 1994. [A genetic algorithm tutorial](https://link.springer.com/article/10.1007/BF00175354). Statistics and Computing, 4(2), pp.65-85.
  * Whitley, D., Dominic, S., Das, R. and Anderson, C.W., 1993. [Genetic reinforcement learning for neurocontrol problems](https://link.springer.com/article/10.1023/A:1022674030396). Machine Learning, 13, pp.259-284.
* Mitchell, M., 1998. [An introduction to genetic algorithms](https://direct.mit.edu/books/book/4675/An-Introduction-to-Genetic-Algorithms). MIT Press.
  * Mitchell, M. and Taylor, C.E., 1999. [Evolutionary computation: An overview](https://www.annualreviews.org/doi/abs/10.1146/annurev.ecolsys.30.1.593). Annual Review of Ecology and Systematics, 30(1), pp.593-616.
  * Mitchell, M., Holland, J. and Forrest, S., 1993. [When will a genetic algorithm outperform hill climbing](https://proceedings.neurips.cc/paper/1993/hash/ab88b15733f543179858600245108dd8-Abstract.html). Advances in Neural Information Processing Systems (pp. 51-58).
* Levine, D., 1997. [Commentary—Genetic algorithms: A practitioner's view](https://pubsonline.informs.org/doi/10.1287/ijoc.9.3.256). INFORMS Journal on Computing, 9(3), pp.256-259.
* Forrest, S., 1993. [Genetic algorithms: Principles of natural selection applied to computation](https://www.science.org/doi/10.1126/science.8346439). Science, 261(5123), pp.872-878.
  * Forrest, S., 1996. [Genetic algorithms](https://dl.acm.org/doi/pdf/10.1145/234313.234350). ACM Computing Surveys, 28(1), pp.77-80.
* Goldberg, D.E., 1989. [Genetic algorithms in search, optimization and machine learning](https://www.goodreads.com/en/book/show/142613). Reading: Addison-Wesley.
  * Goldberg, D.E. and Holland, J.H., 1988. [Genetic algorithms and machine learning](https://link.springer.com/article/10.1023/A:1022602019183). Machine Learning, 3(2), pp.95-99.
  * Goldberg, D.E., 1994. [Genetic and evolutionary algorithms come of age](https://dl.acm.org/doi/10.1145/175247.175259). Communications of the ACM, 37(3), pp.113-120.
* De Jong, K.A., 1975. [An analysis of the behavior of a class of genetic adaptive systems](https://deepblue.lib.umich.edu/bitstream/handle/2027.42/4507/bab6360.0001.001.pdf). Doctoral Dissertation, University of Michigan.
  * De Jong, K.A., 1992. [Are genetic algorithms funcion optimizer?](https://www.mli.gmu.edu/papers/91-95/92-20.pdf). Parallel Problem Solving from Nature, pp.3-13.
  * De Jong, K.A., 1988. [Learning with genetic algorithms: An overview](https://link.springer.com/article/10.1007/BF00113894). Machine Learning, 3, pp.121-138.
* Holland, J.H., 1962. [Outline for a logical theory of adaptive systems](https://dl.acm.org/doi/10.1145/321127.321128). Journal of the ACM, 9(3), pp.297-314.
  * Holland, J.H., 1992. [Genetic algorithms](https://www.scientificamerican.com/article/genetic-algorithms/). Scientific American, 267(1), pp.66-73.
  * Holland, J.H., 1992. [Adaptation in natural and artificial systems: An introductory analysis with applications to biology, control, and artificial intelligence](https://direct.mit.edu/books/book/2574/Adaptation-in-Natural-and-Artificial-SystemsAn). MIT Press.
  * Holland, J.H., 1975. [Adaptation in natural and artificial systems: An introductory analysis with applications to biology, control, and artificial intelligence](https://direct.mit.edu/books/book/2574/Adaptation-in-Natural-and-Artificial-SystemsAn). University of Michigan Press.
  * Holland, J.H., 1973. [Genetic algorithms and the optimal allocation of trials](https://epubs.siam.org/doi/10.1137/0202009). SIAM Journal on Computing, 2(2), pp.88-105.

## Evolution Strategies (ES)

* Vicol, P., Metz, L. and Sohl-Dickstein, J., 2021, July. [Unbiased gradient estimation in unrolled computation graphs with persistent evolution strategies](http://proceedings.mlr.press/v139/vicol21a.html). In International Conference on Machine Learning (pp. 10553-10563). PMLR.
* Nesterov, Y. and Spokoiny, V., 2017. [Random gradient-free minimization of convex functions](https://link.springer.com/article/10.1007/s10208-015-9296-2). Foundations of Computational Mathematics, 17(2), pp.527-566.
* Ollivier, Y., Arnold, L., Auger, A. and Hansen, N., 2017. [Information-geometric optimization algorithms: A unifying picture via invariance principles](https://www.jmlr.org/papers/v18/14-467.html). Journal of Machine Learning Research, 18(18), pp.1-65.
  * Akimoto, Y. and Hansen, N., 2020. Diagonal acceleration for covariance matrix adaptation evolution strategies. Evolutionary Computation, 28(3), pp.405-435.
  * Hansen, N., Arnold, D.V. and Auger, A., 2015. Evolution strategies. In Springer Handbook of Computational Intelligence (pp. 871-898). Springer, Berlin, Heidelberg.
  * Hansen, N. and Auger, A., 2014. Principled design of continuous stochastic search: From theory to practice. Theory and Principled Methods for the Design of Metaheuristics, pp.145-180.
  * Hansen, N., Müller, S.D. and Koumoutsakos, P., 2003. Reducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation (CMA-ES). Evolutionary Computation, 11(1), pp.1-18.
  * Hansen, N. and Ostermeier, A., 2001. Completely derandomized self-adaptation in evolution strategies. Evolutionary Computation, 9(2), pp.159-195.
  * Hansen, N. and Ostermeier, A., 1996, May. Adapting arbitrary normal mutation distributions in evolution strategies: The covariance matrix adaptation. In Proceedings of IEEE International Conference on Evolutionary Computation (pp. 312-317). IEEE.
* Bäck, T., Foussette, C. and Krause, P., 2013. Contemporary evolution strategies (Vol. 86). Berlin: Springer.
  * Bäck, T., Hoffmeister, F. and Schwefel, H.P., 1991. A survey of evolution strategies. In Proceedings of International Conference on Genetic Algorithms.
* Beyer, H.G. and Schwefel, H.P., 2002. Evolution strategies–A comprehensive introduction. Natural Computing, 1(1), pp.3-52.
  * Beyer, H.G., 2001. The theory of evolution strategies. Springer Science & Business Media.
  * Beyer, H.G., 1995. Toward a theory of evolution strategies: On the benefits of sex—The (μ/μ, λ) theory. Evolutionary Computation, 3(1), pp.81-111.
* Schwefel, H.P., 1984. Evolution strategies: A family of non-linear optimization techniques based on imitating some principles of organic evolution. Annals of Operations Research, 1(2), pp.165-167.
  * Schwefel, H.P., 2012. Ubiquity symposium: Evolutionary computation and the processes of life: Life lessons taught by simulated evolution. Ubiquity, 2012(September), pp.1-9.
  * Schwefel, H.P. and de Brito Mendes, M.A., 2010. 45 years of evolution strategies: Hans-Paul Schwefel interviewed for the genetic argonaut blog. ACM SIGEVOlution, 4(2), pp.2-8.
  * Schwefel, H.P., 2008. An interview with Hans-Paul Schwefel: With an introduction by Günter Rudolph. ACM SIGEVOlution, 3(4), pp.2-5.
  * Schwefel, H.P.P., 1993. Evolution and optimum seeking: The sixth generation. John Wiley & Sons, Inc..
  * Schwefel, H.P., 1988. Evolutionary learning optimum-seeking on parallel computer architectures. In Systems Analysis and Simulation I (pp. 217-225). Springer, New York, NY.
  * Schwefel, H.P., 1988. Collective intelligence in evolving systems. In Ecodynamics (pp. 95-100). Springer, Berlin, Heidelberg.
  * Schwefel, H.P., 1981. Numerical optimization of computer models. John Wiley & Sons, Inc..
* Rechenberg, I., 1989. Evolution strategy: Nature’s way of optimization. In Optimization: Methods and Applications, Possibilities and Limitations (pp. 106-126). Springer, Berlin, Heidelberg.
  * Auger, A., Hansen, N., López-Ibáñez, M. and Rudolph, G., 2022. Tributes to Ingo Rechenberg (1934--2021). ACM SIGEVOlution, 14(4), pp.1-4.
  * Streckenbach, J., Koref, I.S., Rechenberg, I. and Uhlmann, E., 2020. Optimization with the evolution strategy by example of electrical-discharge drilling. Neurocomputing, 391, pp.318-324.
  * Rechenberg, I., 2019, July. Evolution, robotics and the somersaulting spider. In Proceedings of Genetic and Evolutionary Computation Conference (pp. 1-1).
  * Rechenberg, I., 2000. Case studies in evolutionary experimentation and computation. Computer Methods in Applied Mechanics and Engineering, 186(2-4), pp.125-140.
  * Rechenberg, I., 1984. The evolution strategy. A mathematical model of darwinian evolution. In Synergetics—from Microscopic to Macroscopic Order (pp. 122-132). Springer, Berlin, Heidelberg.
  * Rechenberg, I., 1973. Evolutionsstrategie: Optimierung technischer systeme nach prinzipien der biologischen evolution. Frommann-Holzboog Verlag, Stuttgart. [NOTE that this seminal dissertation was not read directly by us since originally written in German. But here we still add it owing to its historically significant contributions to EC/ES.]

## Evolutionary Programming (EP)

* Fogel, D.B., 1999. [An overview of evolutionary programming](https://link.springer.com/chapter/10.1007/978-1-4612-1542-4_5). In Evolutionary Algorithms (pp. 89-109). Springer, New York, NY.
* Fogel, D.B., Fogel, L.J. and Atmar, J.W., 1991, January. [Meta-evolutionary programming](https://ieeexplore.ieee.org/document/186507). In Conference Record of Asilomar Conference on Signals, Systems & Computers (pp. 540-541). IEEE Computer Society.
* Fogel, D.B. and Fogel, L.J., 1995, September. [An introduction to evolutionary programming](https://link.springer.com/chapter/10.1007/3-540-61108-8_28). In European Conference on Artificial Evolution (pp. 21-33). Springer, Berlin, Heidelberg.
* Fogel, L.J., Owens, A.J. and Walsh, M.J., 1966. Artificial intelligence through simulated evolution. John Wiley & Sons Inc.

## Genetic Programming (GP)

* [http://gpbib.cs.ucl.ac.uk/](http://gpbib.cs.ucl.ac.uk/)
* Langdon, W.B., 2020. Genetic programming and evolvable machines at 20. Genetic Programming and Evolvable Machines, 21(1), pp.205-217.
* Langdon, W.B. and Poli, R., 2013. Foundations of genetic programming. Springer Science & Business Media.
* Schmidt, M. and Lipson, H., 2009. Distilling free-form natural laws from experimental data. Science, 324(5923), pp.81-85.
* Banzhaf, W., Nordin, P., Keller, R.E. and Francone, F.D., 1998. Genetic programming: An introduction on the automatic evolution of computer programs and its applications. Morgan Kaufmann Publishers Inc..
* Koza, J.R., 1994. Genetic programming as a means for programming computers by natural selection. Statistics and Computing, 4(2), pp.87-112.
  * Koza, J.R., Bennet, F.H., Andre, D. and Keane, M.A., 1999. Genetic programming III: Automatic synthesis of analog circuits. MIT Press.
  * Koza, J.R., 1994. Genetic programming II: Automatic discovery of reusable programs. MIT Press.
  * Koza, J.R., 1992. Genetic programming: On the programming of computers by means of natural selection. MIT Press.
  * Koza, J.R., 1989, August. Hierarchical genetic algorithms operating on populations of computer programs. In Proceedings of International Joint Conference on Artificial Intelligence (pp. 768-774).
* Cramer, N.L., 1985, July. [A representation for the adaptive generation of simple sequential programs](https://dl.acm.org/doi/10.5555/645511.657085). In Proceedings of International Conference on Genetic Algorithms (pp. 183-187).

## Ant Colony Optimization (ACO)

* https://iridia.ulb.ac.be/~mdorigo/HomePageDorigo/    (This is the official homepage of ACO's inventor Marco Dorigo, which includes much information about ACO.)
* Dorigo, M. and Stützle, T., 2019. Ant colony optimization: Overview and recent advances. Handbook of Metaheuristics, pp.311-351.
* Dorigo, M., Birattari, M. and Stutzle, T., 2006. Ant colony optimization. IEEE Computational Intelligence Magazine, 1(4), pp.28-39.
* Bonabeau, E., Dorigo, M. and Theraulaz, G., 2000. Inspiration for optimization from social insect behaviour. Nature, 406(6791), pp.39-42.
* Bonabeau, E., Dorigo, M. and Theraulaz, G., 1999. Swarm intelligence: From natural to artificial systems. Oxford University Press.
* Dorigo, M. and Gambardella, L.M., 1997. Ant colony system: A cooperative learning approach to the traveling salesman problem. IEEE Transactions on Evolutionary Computation, 1(1), pp.53-66.
* Dorigo, M., Maniezzo, V. and Colorni, A., 1996. Ant system: Optimization by a colony of cooperating agents. IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), 26(1), pp.29-41.
* Gambardella, L.M. and Dorigo, M., 1995. Ant-Q: A reinforcement learning approach to the traveling salesman problem. In International Conference on Machine Learning (pp. 252-260). Morgan Kaufmann.

## Particle Swarm Optimization (PSO)

* Eberhart, R.C., Shi, Y. and Kennedy, J., 2001. Swarm intelligence. Elsevier.
* Kennedy, J. and Eberhart, R., 1995, November. Particle swarm optimization. In Proceedings of International Conference on Neural Networks (Vol. 4, pp. 1942-1948). IEEE.

## Non-dominated Sorting Genetic Algorithm II (NSGA-II)

* Deb, K., Pratap, A., Agarwal, S. and Meyarivan, T.A.M.T., 2002. A fast and elitist multiobjective genetic algorithm: NSGA-II. IEEE Transactions on Evolutionary Computation, 6(2), pp.182-197.

## Multi-Objective Evolutionary Algorithm based on Decomposition (MOEA/D)

* Zhang, Q. and Li, H., 2007. MOEA/D: A multiobjective evolutionary algorithm based on decomposition. IEEE Transactions on Evolutionary Computation, 11(6), pp.712-731.

## CoOperative coEvolutionary Algorithms (COEA)

* Gomez, F., Schmidhuber, J. and Miikkulainen, R., 2008. Accelerated neural evolution through cooperatively coevolved synapses. Journal of Machine Learning Research, 9(31), pp.937-965.
* Panait, L., Tuyls, K. and Luke, S., 2008. Theoretical advantages of lenient learners: An evolutionary game theoretic perspective. Journal of Machine Learning Research, 9, pp.423-457.
* Schmidhuber, J., Wierstra, D., Gagliolo, M. and Gomez, F., 2007. Training recurrent networks by evolino. Neural Computation, 19(3), pp.757-779.
* Gomez, F.J. and Schmidhuber, J., 2005, June. Co-evolving recurrent neurons learn deep memory POMDPs. In Proceedings of Annual Conference on Genetic and Evolutionary Computation (pp. 491-498). ACM.
* Fan, J., Lau, R. and Miikkulainen, R., 2003. Utilizing domain knowledge in neuroevolution. In International Conference on Machine Learning (pp. 170-177).
* Potter, M.A. and De Jong, K.A., 2000. Cooperative coevolution: An architecture for evolving coadapted subcomponents. Evolutionary Computation, 8(1), pp.1-29.
* Gomez, F.J. and Miikkulainen, R., 1999, July. Solving non-Markovian control tasks with neuroevolution. In Proceedings of International Joint Conference on Artificial Intelligence (pp. 1356-1361).
* Moriarty, D.E. and Mikkulainen, R., 1996. Efficient reinforcement learning through symbiotic evolution. Machine Learning, 22(1), pp.11-32.
* Moriarty, D.E. and Miikkulainen, R., 1995. Efficient learning from delayed rewards through symbiotic evolution. In International Conference on Machine Learning (pp. 396-404). Morgan Kaufmann.
* Potter, M.A. and De Jong, K.A., 1994, October. A cooperative coevolutionary approach to function optimization. In International Conference on Parallel Problem Solving from Nature (pp. 249-257). Springer, Berlin, Heidelberg.
* Hillis, W.D., 1990. Co-evolving parasites improve simulated evolution as an optimization procedure. Physica D: Nonlinear Phenomena, 42(1-3), pp.228-234.

## CoMpetitive co-Evolutionary Algorithms (CMEA)

* Ficici, S.G. and Pollack, J.B., 2000. A game-theoretic approach to the simple coevolutionary algorithm. In Parallel Problem Solving from Nature (pp. 467-476). Springer Berlin Heidelberg.
* Ficici, S.G. and Pollack, J.B., 1998, June. Challenges in coevolutionary learning: Arms-race dynamics, open-endedness, and mediocre stable states. In Proceedings of International Conference on Artificial Life (pp. 238-247). Cambridge, MA: MIT Press.
* Rosin, C.D. and Belew, R.K., 1997. New methods for competitive coevolution. Evolutionary Computation, 5(1), pp.1-29.

## Differential Evolution (DE)

* Das, S. and Suganthan, P.N., 2010. Differential evolution: A survey of the state-of-the-art. IEEE Transactions on Evolutionary Computation, 15(1), pp.4-31.
* Storn, R., 1999. System design by constraint adaptation and differential evolution. IEEE Transactions on Evolutionary Computation, 3(1), pp.22-34.
* Storn, R. and Price, K., 1997. Differential evolution–A simple and efficient heuristic for global optimization over continuous spaces. Journal of Global Optimization, 11(4), pp.341-359.

## Estimation of Distribution Algorithms (EDAs)

* Larrañaga, P. and Lozano, J.A. eds., 2001. Estimation of distribution algorithms: A new tool for evolutionary computation. Springer Science & Business Media.

## Natural Evolution Strategies (NES)

* Moritz, P., Nishihara, R., Wang, S., Tumanov, A., Liaw, R., Liang, E., Elibol, M., Yang, Z., Paul, W., Jordan, M.I. and Stoica, I., 2018. [Ray: A distributed framework for emerging AI applications](https://www.usenix.org/conference/osdi18/presentation/moritz). In USENIX Symposium on Operating Systems Design and Implementation (pp. 561-577).
* Salimans, T., Ho, J., Chen, X., Sidor, S. and Sutskever, I., 2017. Evolution strategies as a scalable alternative to reinforcement learning. arXiv preprint arXiv:1703.03864.
* Wierstra, D., Schaul, T., Glasmachers, T., Sun, Y., Peters, J. and Schmidhuber, J., 2014. [Natural evolution strategies](https://jmlr.org/papers/v15/wierstra14a.html). Journal of Machine Learning Research, 15(1), pp.949-980.
* Yi, S., Wierstra, D., Schaul, T. and Schmidhuber, J., 2009, June. [Stochastic search using the natural gradient](https://dl.acm.org/doi/10.1145/1553374.1553522). In Proceedings of International Conference on Machine Learning (pp. 1161-1168).

## Quality Diversity (QD)

* https://quality-diversity.github.io/    (Now it is actively updated by Antoine Cully, Jean-Baptiste Mouret, and Stephane Doncieux.)
* Fontaine, M.C. and Nikolaidis, S., 2021. Differentiable quality diversity. Advances in Neural Information Processing Systems.
* Ecoffet, A., Huizinga, J., Lehman, J., Stanley, K.O. and Clune, J., 2021. First return, then explore. Nature, 590(7847), pp.580-586.
* Chatzilygeroudis, K., Cully, A., Vassiliades, V. and Mouret, J.B., 2021. Quality-diversity optimization: A novel branch of stochastic optimization. In Black Box Optimization, Machine Learning, and No-Free Lunch Theorems (pp. 109-135). Springer, Cham.
* Cully, A. and Demiris, Y., 2018. Quality and diversity optimization: A unifying modular framework. IEEE Transactions on Evolutionary Computation, 22(2), pp.245-259.
* Pugh, J.K., Soros, L.B. and Stanley, K.O., 2016. Quality diversity: A new frontier for evolutionary computation. Frontiers in Robotics and AI, 3, pp.1-17.
* Cully, A., Clune, J., Tarapore, D. and Mouret, J.B., 2015. Robots that can adapt like animals. Nature, 521(7553), pp.503-507.
* Mouret, J.B. and Clune, J., 2015. Illuminating search spaces by mapping elites. arXiv preprint arXiv:1504.04909.
* Lehman, J. and Stanley, K.O., 2011, July. Evolving a diversity of virtual creatures through novelty search and local competition. In Proceedings of Annual Conference on Genetic and Evolutionary Computation (pp. 211-218).

## NeuroEvolution (aka Evolving Neural Networks)

* Stanley, K.O., Clune, J., Lehman, J. and Miikkulainen, R., 2019. Designing neural networks through neuroevolution. Nature Machine Intelligence, 1(1), pp.24-35.
* Jaderberg, M., Czarnecki, W.M., Dunning, I., Marris, L., Lever, G., Castaneda, A.G., Beattie, C., Rabinowitz, N.C., Morcos, A.S., Ruderman, A. and Sonnerat, N., 2019. Human-level performance in 3D multiplayer games with population-based reinforcement learning. Science, 364(6443), pp.859-865.
* Moritz, P., Nishihara, R., Wang, S., Tumanov, A., Liaw, R., Liang, E., Elibol, M., Yang, Z., Paul, W., Jordan, M.I. and Stoica, I., 2018. Ray: A distributed framework for emerging AI applications. In USENIX Symposium on Operating Systems Design and Implementation (pp. 561-577).
* Floreano, D., Dürr, P. and Mattiussi, C., 2008. Neuroevolution: From architectures to learning. Evolutionary Intelligence, 1(1), pp.47-62.
* Stanley, K.O. and Miikkulainen, R., 2002. Evolving neural networks through augmenting topologies. Evolutionary Computation, 10(2), pp.99-127.
* Yao, X., 1999. Evolving artificial neural networks. Proceedings of the IEEE, 87(9), pp.1423-1447.

## Evolutionary/Swarm Robotics

* Floreano, D. and Lipson, H., 2021. [From individual robots to robot societies](https://www.science.org/doi/full/10.1126/scirobotics.abk2787). Science Robotics, 6(56).
* Dorigo, M., Theraulaz, G. and Trianni, V., 2021. Swarm robotics: Past, present, and future. Proceedings of the IEEE, 109(7), pp.1152-1165.
* Kriegman, S., Blackiston, D., Levin, M. and Bongard, J., 2020. A scalable pipeline for designing reconfigurable organisms. Proceedings of the National Academy of Sciences, 117(4), pp.1853-1859.
* Dorigo, M., Theraulaz, G. and Trianni, V., 2020. Reflections on the future of swarm robotics. Science Robotics, 5(49).
* Howard, D., Eiben, A.E., Kennedy, D.F., Mouret, J.B., Valencia, P. and Winkler, D., 2019. Evolving embodied intelligence from materials to machines. Nature Machine Intelligence, 1(1), pp.12-19.
* Doncieux, S., Bredeche, N., Mouret, J.B. and Eiben, A.E.G., 2015. Evolutionary robotics: What, why, and where to. Frontiers in Robotics and AI, 2, p.4.
* Bongard, J. and Lipson, H., 2014. Evolved machines shed light on robustness and resilience. Proceedings of the IEEE, 102(5), pp.899-914.
* Bongard, J.C., 2013. Evolutionary robotics. Communications of the ACM, 56(8), pp.74-83.
* Pfeifer, R. and Bongard, J., 2007. How the body shapes the way we think: A new view of intelligence. MIT Press.
* Nolfi, S. and Floreano, D., 2000. Evolutionary robotics: The biology, intelligence, and technology of self-organizing machines. MIT Press.
* Lipson, H. and Pollack, J.B., 2000. Automatic design and manufacture of robotic lifeforms. Nature, 406(6799), pp.974-978.
* Sims, K., 1995. Evolving 3D morphology and behavior by competition. Artificial Life, 1(4), pp.353-372.
* Sims, K., 1994, July. Evolving virtual creatures. In Proceedings of Annual Conference on Computer Graphics and Interactive Techniques (pp. 15-22).
* Reynolds, C.W., 1987, August. Flocks, herds and schools: A distributed behavioral model. In Proceedings of Annual Conference on Computer Graphics and Interactive Techniques (pp. 25-34).

## Evolutionary Design

* Bentley, P., 1999. [Evolutionary design by computers](https://www.amazon.com/Evolutionary-Design-Computers-Peter-Bentley/dp/155860605X). Morgan Kaufmann.

## Broader Viewpoints From CS/AI/ML/Optimization

* Zador, A., Escola, S., Richards, B., Ölveczky, B., Bengio, Y., Boahen, K., Botvinick, M., Chklovskii, D., Churchland, A., Clopath, C. and DiCarlo, J., 2023. [Catalyzing next-generation Artificial Intelligence through NeuroAI](https://www.nature.com/articles/s41467-023-37180-x). Nature Communications, 14(1), p.1597.
  * "Put another way, we can greatly accelerate our search for general-purpose circuits for realworld interaction by taking advantage of the optimization process that evolution has already engaged in."
    * Stanley, K. O., Clune, J., Lehman, J. & Miikkulainen, R. Designing neural networks through neuroevolution. Nat. Mach. Intell. 1, 24–35 (2019).
    * Gupta, A., Savarese, S., Ganguli, S. & Fei-Fei, L. Embodied intelligence via learning and evolution. Nat. Commun. 12, 5721 (2021).
* Turner, R., Eriksson, D., McCourt, M., Kiili, J., Laaksonen, E., Xu, Z. and Guyon, I., 2021, August. [Bayesian optimization is superior to random search for machine learning hyperparameter tuning: Analysis of the black-box optimization challenge 2020](http://proceedings.mlr.press/v133/turner21a/turner21a.pdf). In NeurIPS 2020 Competition and Demonstration Track (pp. 3-26). PMLR. [ https://bbochallenge.com/ ]
* Millhouse, T., Moses, M. and Mitchell, M., 2021. Foundations of intelligence in natural and artificial systems: A workshop report. arXiv preprint arXiv:2105.02198.
* [https://www.quantamagazine.org/computers-evolve-a-new-path-toward-human-intelligence-20191106/](https://www.quantamagazine.org/computers-evolve-a-new-path-toward-human-intelligence-20191106/)
* Clune, J., 2019. AI-GAs: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence. arXiv preprint arXiv:1905.10985.
* Kerschke, P., Hoos, H.H., Neumann, F. and Trautmann, H., 2019. Automated algorithm selection: Survey and perspectives. Evolutionary Computation, 27(1), pp.3-45.
* Forrest, S. and Mitchell, M., 2016. Adaptive computation: The multidisciplinary legacy of John H. Holland. Communications of the ACM, 59(8), pp.58-63.
* Domingos, P., 2015. The master algorithm: How the quest for the ultimate learning machine will remake our world. Basic Books.
  * Domingos, P., 2015. The five tribes of machine learning and what you can take from each. ACM Learning Center. [ [www](https://learning.acm.org/techtalks/machinelearning) | [pdf](https://learning.acm.org/binaries/content/assets/leaning-center/webinar-slides/2015/five-tribes-ml_112415.pdf) ]
* Stulp, F. and Sigaud, O., 2012, June. [Path integral policy improvement with covariance matrix adaptation](https://icml.cc/2012/papers/171.pdf). In International Coference on International Conference on Machine Learning (pp. 1547-1554).
* Floreano, D. and Mattiussi, C., 2008. Bio-inspired artificial intelligence: Theories, methods, and technologies. MIT Press.
* Wolpert, D.H. and Macready, W.G., 1997. No free lunch theorems for optimization. IEEE Transactions on Evolutionary Computation, 1(1), pp.67-82.
* Conrad, M. and Rizki, M.M., 1989. [The artificial worlds approach to emergent evolution](https://www.sciencedirect.com/science/article/abs/pii/0303264789900324). BioSystems, 23(2-3), pp.247-258.
* Axelrod, R., 1987. The evolution of strategies in the iterated prisoner’s dilemma. Genetic Algorithms and Simulated Annealing.
* Bremermann, H.J., 1968. Numerical optimization procedures derived from biological evolution processes. Cybernetic Problems in Bionics, pp.597-616.
* Fogel, D.B., 2006. Nils barricelli-artificial life, coevolution, self-adaptation. IEEE Computational Intelligence Magazine, 1(1), pp.41-45.
* Turing, A., 1948. Intelligent machinery. In The Essential Turing. Oxford University Press.
  * Copeland, B.J. ed., 2004. [The essential Turing: Seminal writings in computing, logic, philosophy, artificial intelligence, and artificial life plus the secrets of enigma](https://global.oup.com/academic/product/the-essential-turing-9780198250807). Oxford University Press.
